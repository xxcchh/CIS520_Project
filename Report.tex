\documentclass[]{article}
\usepackage{amsfonts,amssymb,amsmath}
%\documentstyle[12pt,amsfonts]{article}
%\documentstyle{article}
\usepackage{biblatex}

\setlength{\topmargin}{-.5in}
\setlength{\oddsidemargin}{0 in}
\setlength{\evensidemargin}{0 in}
\setlength{\textwidth}{6.5truein}
\setlength{\textheight}{8.5truein}
\setcounter{MaxMatrixCols}{16}
%\input ../basicmath/basicmathmac.tex
%
%\input ../adgeomcs/lamacb.tex
\input ./mac-new.tex
\input ./mathmac-v2.tex
%\input ../adgeomcs/mac.tex
%\input ../adgeomcs/mathmac.tex

\def\fseq#1#2{(#1_{#2})_{#2\geq 1}}
\def\fsseq#1#2#3{(#1_{#3(#2)})_{#2\geq 1}}
\def\qleq{\sqsubseteq}

%
\begin{document}

\title{CIS520 Report: ML Crackers}   % type title between braces
\author{Francine Leech, Ziyin Qu, Chen Xiang}         % type author(s) between braces
\date{December 12, 2016}    % type date between braces
\maketitle

\section{Introduction}


\section{Preliminary Methods}
- eveyrthing tyat didn't work
- why it didnt work 
- image - Ziyin
- PCA/GMM 
- Other ensemble methods methods


\section{Main Methods}

\subsection{Naive Bayes}
Accuracy

The second main

\subsection{GentleBoost}
The second main method we utilized was an ensemble method. We used GentleBoost, a weak learning that was built by MATLAB under the fitensemble function. The method combines many weak learners into one high quality ensemble predictor. We chose this ensemble methods over the others offered by MATLAB, because it is preforms well with binary classification trees with many predictors (ensemble citation). \\

The input of the model was the $word_train$ data. We used a 10-fold cross validation method to observed how the model preformed, specified the use 300 learners, and the type of learner as 'tree'. The average cross validation error was 0.21. The algorithm classified joy and sadness well. \\

The method could have improved if we increased the number of learners, however it would have taken a very long time to train because the data is large. Initially we tried the method with the default number of learners, 100 trees, and found that the cross validation accuracy only improved slightly. This slight improvement with triple number of learners reveals that the data has some intricacies or patterns that the ensemble method cannot learn.   


\subsection{Support Vector Machine}



Accuracy 

Table with all accuracy 

\section{Ensemble Method}
Ensembl: Sentiment Analysis 1 + Methods \\
(1) First, we use vader package in python to do sentimental analysis on each word shown on topwords list. Vader is a lexicon and rule-based sentiment analysis tool that is specifically attuned to sentiments expressed in social media.
The input is the every word in topwords list and the output is the probability of negative, positive and neutral emotion that this word may express. \\
The output often looks like this, when type "funny" we can see \{'compound': 0.4404, 'neg': 0.0, 'neu': 0.0, 'pos': 1.0\}, which means it is an extremely postive word. \\
(2) Second, we attach those scores to every word in topwords list. The advantage is that, we can use this preliminary method to choose the extremely positive and extremely negative sentences by assuming that there are no
extreme postive words shown in negative sentences and vise versa. 

Ensembl: Sentiment Analysis 2 + Methods
dictionry wasn't as good \\
From the raw tweets we notice that there are some words begin with "#", which may represent the topic this sentence belongs to. It is useful since some specific topics always express similar emotions, like "#family" usually means positive.
So instead of anaylizing the sentiment of each word, we can use sentence as the input and in this way get the average emotion scores of each word.\\
(1) First, do sentimental analysis on each sentence in raw tweets. For all the words that appear in this sentence, attach the result score to this words. \\
(2) Second, for every word we can get the average emotion score based on all the sentences that they have shown.





\section{Discussion}

\section{Works Cited}
\begin{thebibliography}{1}

%\bibitem{ensemble} Documentation. Ensemble Methods - MATLAB & Simulink. N.p., n.d. Web. 11 Dec. 2016. 

\end{thebibliography}

\end{document}
